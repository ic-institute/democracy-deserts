{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1fbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of charter cities\n",
    "charter_cities_path = 'data/cacities/charter-cities.txt'\n",
    "\n",
    "with open(charter_cities_path) as f:\n",
    "    charter_cities = { line.strip() for line in f }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6c02d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_geoname(geoname):\n",
    "    r = dict(state='', name='', geotype='')\n",
    "    \n",
    "    # e.g. state data\n",
    "    if ', ' not in geoname:\n",
    "        r['state'] = geoname\n",
    "        return r\n",
    "    \n",
    "    rest, r['state'] = geoname.rsplit(', ', 1)\n",
    "\n",
    "    # missing geotype (e.g. \"Princeton, New Jersey\")\n",
    "    #\n",
    "    # doesn't seem to happen in California\n",
    "    if ' ' not in rest:\n",
    "        r['name'] = rest\n",
    "        return r\n",
    "    \n",
    "    clarification = ''\n",
    "    # e.g. \"Bayview CDP (Contra Costa County), California\"\n",
    "    if rest.endswith(')') and '(' in rest:\n",
    "        rest = rest[:-1]\n",
    "        rest, clarification = rest.rsplit(' (', 1)\n",
    "        \n",
    "    r['name'], r['geotype'] = rest.rsplit(' ', 1)\n",
    "    \n",
    "    if clarification:\n",
    "        r['name'] = f\"{r['name']} ({clarification})\"\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f478285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_process_place_rows(rows, charter_cities=()):\n",
    "    for row in rows:\n",
    "        # skip race/ethnicity breakdowns\n",
    "        if row['lnnumber'] != '1':\n",
    "            continue\n",
    "            \n",
    "        # don't need this, all rows are the same\n",
    "        del row['lnnumber']\n",
    "        del row['lntitle']\n",
    "            \n",
    "        if 'California' not in row['geoname']:\n",
    "            continue\n",
    "        \n",
    "        row.update(parse_geoname(row['geoname']))\n",
    "        \n",
    "        if row['state'] != 'California':\n",
    "            continue\n",
    "\n",
    "        yield row        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d4a8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep CA data only, exclude breakdown by race/ethnicity\n",
    "import csv\n",
    "\n",
    "cvap_places_path = 'data/census/CVAP_2015-2019_ACS_csv_files/Place.csv'\n",
    "\n",
    "f = open(cvap_places_path, newline='', encoding='latin-1')\n",
    "reader = csv.DictReader(f)\n",
    "\n",
    "ca_places_list = list(filter_and_process_place_rows(reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b8208fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame.from_dict(ca_places_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2f898a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geoname', 'geoid', 'tot_est', 'tot_moe', 'adu_est', 'adu_moe',\n",
       "       'cit_est', 'cit_moe', 'cvap_est', 'cvap_moe', 'state', 'name',\n",
       "       'geotype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bamboolib",
   "language": "python",
   "name": "bamboolib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
